"use strict";(self.webpackChunkmy_page=self.webpackChunkmy_page||[]).push([[61249],{715:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>t,contentTitle:()=>s,default:()=>z,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"security-engineer-docs/zgodnosc/ai-act","title":"Ai act","description":"AI Act to europejskie rozporz\u0105dzenie maj\u0105ce na celu uregulowanie rozwoju i stosowania system\xf3w sztucznej inteligencji. Z perspektywy Security Engineera oznacza to nowe obowi\u0105zki w zakresie oceny ryzyka, nadzoru nad modelami AI oraz zapewnienia zgodno\u015bci z przepisami dotycz\u0105cymi bezpiecze\u0144stwa, przejrzysto\u015bci i etyki.","source":"@site/docs/security-engineer-docs/04-zgodnosc/ai-act.md","sourceDirName":"security-engineer-docs/04-zgodnosc","slug":"/security-engineer-docs/zgodnosc/ai-act","permalink":"/docs/security-engineer-docs/zgodnosc/ai-act","draft":false,"unlisted":false,"editUrl":"https://github.com/przemyslvw/my-page/edit/master/docs/security-engineer-docs/04-zgodnosc/ai-act.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ai-act","title":"Ai act","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"04 Zgodnosc","permalink":"/docs/category/04-zgodnosc"},"next":{"title":"Audyty i polityki","permalink":"/docs/security-engineer-docs/zgodnosc/audyty-i-polityki"}}');var o=n(74848),c=n(28453);const r={id:"ai-act",title:"Ai act",sidebar_position:1},s=void 0,t={},d=[{value:"\ud83d\udcd8 Czym jest AI Act?",id:"-czym-jest-ai-act",level:2},{value:"\ud83d\uded1 Kategorie ryzyka",id:"-kategorie-ryzyka",level:2},{value:"\ud83d\udd10 Wymogi bezpiecze\u0144stwa",id:"-wymogi-bezpiecze\u0144stwa",level:2},{value:"\ud83e\udde0 Obowi\u0105zki organizacji",id:"-obowi\u0105zki-organizacji",level:2},{value:"\ud83d\udee0\ufe0f Rola Security Engineera",id:"\ufe0f-rola-security-engineera",level:2},{value:"\u2705 Dobre praktyki",id:"-dobre-praktyki",level:2}];function l(e){const i={blockquote:"blockquote",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,c.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(i.p,{children:"AI Act to europejskie rozporz\u0105dzenie maj\u0105ce na celu uregulowanie rozwoju i stosowania system\xf3w sztucznej inteligencji. Z perspektywy Security Engineera oznacza to nowe obowi\u0105zki w zakresie oceny ryzyka, nadzoru nad modelami AI oraz zapewnienia zgodno\u015bci z przepisami dotycz\u0105cymi bezpiecze\u0144stwa, przejrzysto\u015bci i etyki."}),"\n",(0,o.jsx)(i.h2,{id:"-czym-jest-ai-act",children:"\ud83d\udcd8 Czym jest AI Act?"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Rozporz\u0105dzenie Parlamentu Europejskiego i Rady UE reguluj\u0105ce wykorzystanie AI w UE"}),"\n",(0,o.jsx)(i.li,{children:"Wprowadza klasyfikacj\u0119 system\xf3w AI wed\u0142ug poziomu ryzyka (minimalne, ograniczone, wysokie, zakazane)"}),"\n",(0,o.jsx)(i.li,{children:"Dotyczy producent\xf3w, dostawc\xf3w i u\u017cytkownik\xf3w system\xf3w AI, r\xf3wnie\u017c poza UE je\u015bli AI wp\u0142ywa na obywateli UE"}),"\n",(0,o.jsxs)(i.li,{children:["Wymusza ",(0,o.jsx)(i.strong,{children:"compliance-by-design"})," oraz silne mechanizmy audytu i nadzoru"]}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"-kategorie-ryzyka",children:"\ud83d\uded1 Kategorie ryzyka"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Niedozwolone (zakazane)"}),": systemy manipuluj\u0105ce zachowaniem (np. ocena spo\u0142ecze\u0144stwa, podprogowe oddzia\u0142ywanie)"]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Wysokiego ryzyka"}),": AI w obszarach takich jak biometria, rekrutacja, infrastruktura krytyczna, systemy s\u0105downicze"]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Ograniczonego ryzyka"}),": chatboty, systemy rekomendacji \u2013 musz\u0105 spe\u0142nia\u0107 wymogi przejrzysto\u015bci"]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Minimalne ryzyko"}),": np. AI w grach, spam-filtry \u2013 niepodlegaj\u0105ce regulacji"]}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"-wymogi-bezpiecze\u0144stwa",children:"\ud83d\udd10 Wymogi bezpiecze\u0144stwa"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Ocena ryzyka AI przed wdro\u017ceniem i w cyklu \u017cycia (continuous risk assessment)"}),"\n",(0,o.jsx)(i.li,{children:"Zabezpieczenia przed nadu\u017cyciami: manipulacj\u0105, diskriminacj\u0105, eskalacj\u0105 uprawnie\u0144"}),"\n",(0,o.jsx)(i.li,{children:"Dokumentacja techniczna (m.in. opis architektury, danych ucz\u0105cych, test\xf3w)"}),"\n",(0,o.jsx)(i.li,{children:"Rejestrowanie dzia\u0142a\u0144 AI (logi, metadane, decyzje)"}),"\n",(0,o.jsx)(i.li,{children:"Ograniczenie dost\u0119pu do modeli i danych \u2013 uwzgl\u0119dnienie bezpiecze\u0144stwa infrastruktury"}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"-obowi\u0105zki-organizacji",children:"\ud83e\udde0 Obowi\u0105zki organizacji"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Wdro\u017cenie systemu zarz\u0105dzania ryzykiem AI (AI Risk Management System)"}),"\n",(0,o.jsx)(i.li,{children:"Prowadzenie audyt\xf3w technicznych i etycznych modeli"}),"\n",(0,o.jsx)(i.li,{children:"Szkolenie personelu technicznego i operacyjnego"}),"\n",(0,o.jsx)(i.li,{children:"Zg\u0142aszanie incydent\xf3w i niezgodno\u015bci do organ\xf3w nadzorczych"}),"\n",(0,o.jsx)(i.li,{children:"Wsp\xf3\u0142praca z Data Protection Officer i zespo\u0142em ds. zgodno\u015bci"}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"\ufe0f-rola-security-engineera",children:"\ud83d\udee0\ufe0f Rola Security Engineera"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Identyfikacja system\xf3w AI w organizacji i klasyfikacja ryzyka"}),"\n",(0,o.jsx)(i.li,{children:"Wsp\xf3\u0142praca z zespo\u0142em ds. AI/ML przy audytach bezpiecze\u0144stwa modeli"}),"\n",(0,o.jsx)(i.li,{children:"Zapewnienie odpowiedniej segregacji danych i kontroli dost\u0119pu do modeli"}),"\n",(0,o.jsx)(i.li,{children:"Monitorowanie dzia\u0142ania system\xf3w AI pod k\u0105tem bezpiecze\u0144stwa i nadu\u017cy\u0107"}),"\n",(0,o.jsx)(i.li,{children:"Tworzenie polityk wewn\u0119trznych dot. bezpiecznego u\u017cycia AI"}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"-dobre-praktyki",children:"\u2705 Dobre praktyki"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Tw\xf3rz zbi\xf3r zasad \u201eResponsible AI\u201d z perspektywy bezpiecze\u0144stwa"}),"\n",(0,o.jsx)(i.li,{children:"Stosuj Privacy by Design i Security by Design tak\u017ce w modelach ML"}),"\n",(0,o.jsx)(i.li,{children:"Przechowuj i analizuj logi inferencji (jak model podejmowa\u0142 decyzj\u0119)"}),"\n",(0,o.jsx)(i.li,{children:"Wdra\u017caj sandboxing i detekcj\u0119 nadu\u017cy\u0107 (np. adversarial inputs)"}),"\n",(0,o.jsx)(i.li,{children:"Upewnij si\u0119, \u017ce systemy AI nie obchodz\u0105 istniej\u0105cych mechanizm\xf3w bezpiecze\u0144stwa"}),"\n"]}),"\n",(0,o.jsxs)(i.blockquote,{children:["\n",(0,o.jsx)(i.p,{children:"AI Act to nie tylko regulacja \u2013 to konieczno\u015b\u0107, by budowa\u0107 bezpieczne, odpowiedzialne i odporne na nadu\u017cycia systemy sztucznej inteligencji."}),"\n"]})]})}function z(e={}){const{wrapper:i}={...(0,c.R)(),...e.components};return i?(0,o.jsx)(i,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},28453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>s});var a=n(96540);const o={},c=a.createContext(o);function r(e){const i=a.useContext(c);return a.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function s(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),a.createElement(c.Provider,{value:i},e.children)}}}]);